{
    "build": {
        "dockerfile": "Dockerfile",
        "context": ".."
    },
    "runArgs": [
        "--gpus=all",
        "--network",
        "ollama_network",
        "--name",
        "devcontainer_ollama"
    ],
    "initializeCommand": "docker network rm ollama_network && docker network create ollama_network",
    "postStartCommand": "ollama serve & sleep 5 && ollama run llama3"
}