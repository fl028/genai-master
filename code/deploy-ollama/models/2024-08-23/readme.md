# llama3.1-finetuned-2024-08-23
- 10k training rows (8725)
- adapted parameters 83 Mio
- training time (training.py) 5h
- azure costs up to then ??â‚¬